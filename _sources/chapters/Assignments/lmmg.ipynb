{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lecture: NLP and LLMs in Data Driven Investing**\n",
    "**Prof. [Your Name]** | *Fin418: Data Driven Investing*\n",
    "\n",
    "## **Overview**\n",
    "In this lecture, we explore how Natural Language Processing (NLP) and Large Language Models (LLMs) can be utilized to extract signals from unstructured financial data.\n",
    "\n",
    "**Agenda:**\n",
    "1.  **Document Similarity:** Analyzing the shift in FedEx's narrative during the early pandemic (Q1 vs Q2 2020) using TF-IDF.\n",
    "2.  **Sentiment Analysis with LLMs:** Using `FinBERT` to quantify the tone of Federal Reserve (FOMC) statements during the crisis.\n",
    "3.  **The Look-Ahead Bias Trap:** A simulation demonstrating the most common pitfall when backtesting LLM-based strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup and Libraries\n",
    "# We install 'transformers' for the LLM and 'wordcloud' for visualization\n",
    "!pip install transformers torch wordcloud matplotlib seaborn pandas scikit-learn -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from wordcloud import WordCloud\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set plotting style for the course\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "print(\"Libraries installed and imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. Earnings Call Analysis: FedEx (FDX)**\n",
    "\n",
    "Earnings calls provide management's raw perspective on operations. We will compare two critical periods for FedEx using **Cosine Similarity** to measure how \"distant\" the narratives are.\n",
    "\n",
    "* **Period A (March 2020):** Peak uncertainty, start of lockdowns.\n",
    "* **Period B (June 2020):** Adaptation, rise of e-commerce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 The Data: Excerpts from FedEx Earnings Calls\n",
    "# In a real application, you would scrape these via an API (e.g., FMP or SeekingAlpha)\n",
    "\n",
    "fdx_march_2020 = \"\"\"\n",
    "We said on this call last year that FY 2020 would be a year of challenge and change.\n",
    "Then beginning in January, we began to deal with COVID-19 in China then in Europe and then, of course, in the United States.\n",
    "We've made every effort to keep our team members and the public safe as we've dealt with this terrible disease.\n",
    "We are suspending our earnings forecast. The economic impact of the coronavirus is hard to predict.\n",
    "Global trade has slowed significantly due to the shutdowns.\n",
    "\"\"\"\n",
    "\n",
    "fdx_june_2020 = \"\"\"\n",
    "Here in the United States, the COVID pandemic has accelerated e-commerce adoption.\n",
    "In mid-March, Asia-Pacific outbound average daily volume grew substantially over pre-COVID-19 levels fueled by PPE demand surge.\n",
    "We are also experiencing Europe outbound growth on the transatlantic lane due to limited capacity and surging e-commerce volume.\n",
    "As we enter fiscal 21, there are signs of tentative economic recovery under way.\n",
    "We have continued to champion small and medium businesses and support their recovery.\n",
    "\"\"\"\n",
    "\n",
    "# 2.2 Vectorization (TF-IDF) and Similarity\n",
    "# We convert text to numbers, highlighting unique words (like \"PPE\" or \"suspending\")\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform([fdx_march_2020, fdx_june_2020])\n",
    "\n",
    "# Calculate Similarity\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "\n",
    "print(f\"Cosine Similarity between March and June Calls: {similarity[0][0]:.4f}\")\n",
    "print(\"\\nInterpretation: A low score indicates a massive shift in the company's operating environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. Application: FOMC Sentiment with FinBERT**\n",
    "\n",
    "Standard dictionary approaches (counting \"positive\" vs \"negative\" words) often fail in finance because context matters. We will use **FinBERT**, a Large Language Model fine-tuned specifically on financial text, to analyze Federal Reserve statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Load the FOMC Text Data\n",
    "fomc_march_15 = \"\"\"\n",
    "The coronavirus outbreak has harmed communities and disrupted economic activity in many countries, including the United States.\n",
    "The Federal Reserve is prepared to use its full range of tools to support the flow of credit to households and businesses.\n",
    "\"\"\"\n",
    "\n",
    "fomc_april_29 = \"\"\"\n",
    "The Federal Reserve is committed to using its full range of tools to support the U.S. economy in this challenging time.\n",
    "The ongoing public health crisis will weigh heavily on economic activity, employment, and inflation in the near term.\n",
    "\"\"\"\n",
    "\n",
    "fomc_data = pd.DataFrame({\n",
    "    'Date': ['2020-03-15', '2020-04-29'],\n",
    "    'Text': [fomc_march_15, fomc_april_29]\n",
    "})\n",
    "\n",
    "# 3.2 Load FinBERT\n",
    "# Note: This downloads the model weights from Hugging Face\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# 3.3 Apply the Model\n",
    "print(\"Running LLM inference...\")\n",
    "def get_sentiment(text):\n",
    "    # The model returns a label (Positive/Negative/Neutral) and a confidence score\n",
    "    result = classifier(text)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "fomc_data[['Label', 'Score']] = fomc_data['Text'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
    "\n",
    "display(fomc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. The Pitfall: Look-Ahead Bias**\n",
    "\n",
    "The most critical error in Data Driven Investing is **Look-Ahead Bias**.\n",
    "\n",
    "When using LLMs, this happens if you align today's news with today's return. In reality, news often happens *during* or *after* market hours. If you trade at the **Open**, you cannot use news released at **Noon**.\n",
    "\n",
    "Below is a simulation of this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Simulate Data\n",
    "np.random.seed(42)\n",
    "n_days = 200\n",
    "dates = pd.date_range(start='2020-01-01', periods=n_days)\n",
    "\n",
    "# Generate synthetic returns and sentiment\n",
    "# Assumption: Sentiment has predictive power for TOMORROW's return\n",
    "sentiment = np.random.choice([-1, 1], n_days) # -1 (Bad News), 1 (Good News)\n",
    "noise = np.random.normal(0, 0.01, n_days)\n",
    "\n",
    "# The Return generation process:\n",
    "# Return(t) is driven by Sentiment(t-1) [Predictive] AND Sentiment(t) [Reactionary]\n",
    "returns = (0.5 * np.roll(sentiment, 1) * 0.01) + noise\n",
    "df = pd.DataFrame({'Date': dates, 'Return': returns, 'Sentiment': sentiment}).iloc[1:]\n",
    "\n",
    "# 4.2 The \"Flawed\" Strategy (Look-Ahead)\n",
    "# We trade using the sentiment of the SAME day (assuming we knew the news before the market opened)\n",
    "df['Strategy_LookAhead'] = df['Sentiment'] * df['Return']\n",
    "\n",
    "# 4.3 The \"Correct\" Strategy (Lagged)\n",
    "# We trade using YESTERDAY'S sentiment (we read the news, then trade the next open)\n",
    "df['Strategy_Real'] = df['Sentiment'].shift(1) * df['Return']\n",
    "\n",
    "# 4.4 Visualization\n",
    "df['Cum_Ret_LookAhead'] = (1 + df['Strategy_LookAhead']).cumprod()\n",
    "df['Cum_Ret_Real'] = (1 + df['Strategy_Real']).cumprod()\n",
    "df['Cum_Ret_Market'] = (1 + df['Return']).cumprod()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Date'], df['Cum_Ret_LookAhead'], label='Look-Ahead Bias (Flawed)', color='red', linewidth=2, linestyle='--')\n",
    "plt.plot(df['Date'], df['Cum_Ret_Real'], label='Realistic Strategy (Lagged)', color='green', linewidth=2)\n",
    "plt.plot(df['Date'], df['Cum_Ret_Market'], label='Market (Buy & Hold)', color='gray', alpha=0.5)\n",
    "\n",
    "plt.title(\"The Danger of Look-Ahead Bias in NLP Strategies\", fontsize=16)\n",
    "plt.ylabel(\"Cumulative Return ($1 Invested)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: The Red line is a fantasy. The Green line is reality.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
